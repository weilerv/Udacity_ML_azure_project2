
# Project: Operationalizing Machine Learning

The first goal of this project is to use Azure to configure a cloud-based machine learning production model, delpoy it and consume it, the second part is about creating, publishing and consuming a pipeline. 
We used the Bank Marketing dataset

## Architectural Diagram
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/68106426-694e-4b6b-9309-578bbecae839)

## Key Steps
### 1. Authentication
Used Udacity Lab so no need ofr this step
### 2. AutoML run
* Create new AutoMl run
* Select and upload Bankmarketing dataset
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/40a5a206-f144-416a-bce6-53787f926268)

* Create new AutoMl experiment
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/8bf45de1-4e89-446b-a273-2f9347361b65)

* Create new compute cluster
* Run the experiment 

* Best model:
  
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/8908be82-56c7-42f0-9929-2207b86ad55a)

### 3. Deploy best model
This step allows to interact with the HTTP API service and interact with the model by sending data over POST requests.
* on ACI and authentication enabled

### 4. Enable logging (Application Insight)
This steps ensures to detect anomalies and to visualize performance.
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/c205e362-7aa3-43c0-b507-0d7c59a8ff11)
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/edf012cd-f379-40ec-ab51-b616dc968152)

*  download config.json from Azure ML and upload to same folder as logs.py
*  change the deployment name in logs.py
*  run from terminal logs.py to enable logging

### 5. Swagger
* download swagger.json from deployment
* run bash swagger.sh after modifying 8000 to 9000, swagger Ui can be found in localhost:9000
* run python serve.py, insert http://localhost:8000/swagger.json
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/f5c322c0-0fef-41bf-bdbb-b53dda5a6bae)


### 6. Consume Model Endpoints
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/afc98b24-474d-474d-9888-05033e07711b)
* after inserting scoring_uri and key from deployment to endpoint.py, run it

### 7. Create, publish, consume pipeline
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/8f49732b-b363-4572-a527-4e2e59a0c85c)
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/f29a2f83-61ba-47f7-8061-e3e5dc088803)
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/392f863a-70be-4935-9328-1b8d1605d536)
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/cb13cba4-db7a-4835-913f-364e117e9eac)
![image](https://github.com/weilerv/Udacity_ML_azure_project2/assets/37341293/bba0688f-371e-41ec-829e-fee54fe5b630)



## Screen Recording
link to the recording (*company policy did not allow to take screencast recording so recorded it by my phone)

## Improvement ideas 
* better data cleaning and wrangling
* longer run time and bigger cluster size could improve the model generated by autoML, also deep learning could be included
